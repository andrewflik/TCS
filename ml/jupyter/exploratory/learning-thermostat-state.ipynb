{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import urllib.request\n",
    "train_file = \"datasets/thermostat/sample-training-data.csv\"\n",
    "test_file = \"datasets/thermostat/test-data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "COLUMNS = [\"month\", \"day\", \"hour\", \"min\", \"pirstatus\",\n",
    "           \"isDay\", \"extTemp\", \"extHumidity\", \"loungeTemp\", \"loungeHumidity\",\n",
    "           \"state\", \"temperature\", \"label\"]\n",
    "df_train = pd.read_csv(train_file, names=COLUMNS, skipinitialspace=True)\n",
    "df_test = pd.read_csv(test_file, names=COLUMNS, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = []\n",
    "CONTINUOUS_COLUMNS = [\"month\",\"day\", \"hour\", \"min\", \"pirstatus\",\n",
    "                      \"isDay\", \"extTemp\", \"extHumidity\", \"loungeTemp\", \"loungeHumidity\"\n",
    "           ]\n",
    "LABEL_COLUMN=\"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  day  hour  min  pirstatus  isDay  extTemp  extHumidity  loungeTemp  \\\n",
      "0     12   12     0    0          1      0       19           52        19.5   \n",
      "1     12   12     9    0          0      1       19           52        18.0   \n",
      "2     12   12    10    0          0      1       21           52        19.0   \n",
      "3     12   12    14    0          0      1       24           52        22.0   \n",
      "4     12   12    16    0          1      1       23           52        22.0   \n",
      "\n",
      "   loungeHumidity  state  temperature  label  \n",
      "0              53      0           26      0  \n",
      "1              53      0           26      0  \n",
      "2              53      0           26      0  \n",
      "3              53      1           24      1  \n",
      "4              53      1           24      1  \n"
     ]
    }
   ],
   "source": [
    "df_train[LABEL_COLUMN] = df_train[\"state\"]\n",
    "df_test[LABEL_COLUMN] = df_test[\"state\"]\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def input_fn(df):\n",
    "  # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "  # the values of that column stored in a constant Tensor.\n",
    "  continuous_cols = {k: tf.constant(df[k].values)\n",
    "                     for k in CONTINUOUS_COLUMNS}\n",
    "  # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "  # to the values of that column stored in a tf.SparseTensor.\n",
    "  categorical_cols = {k: tf.SparseTensor(\n",
    "      indices=[[i, 0] for i in range(df[k].size)],\n",
    "      values=df[k].values.astype(str),\n",
    "      dense_shape=[df[k].size, 1])\n",
    "                      for k in CATEGORICAL_COLUMNS}\n",
    "  # Merges the two dictionaries into one.\n",
    "  feature_cols = dict()\n",
    "  feature_cols.update(continuous_cols.copy())\n",
    "  feature_cols.update(categorical_cols.copy())\n",
    "  #feature_cols = dict(continuous_cols.items() + categorical_cols.items())\n",
    "  # Converts the label column into a constant Tensor.\n",
    "  label = tf.constant(df[LABEL_COLUMN].values)\n",
    "  # Returns the feature columns and the label.\n",
    "  return feature_cols, label\n",
    "\n",
    "def train_input_fn():\n",
    "  return input_fn(df_train)\n",
    "\n",
    "def eval_input_fn():\n",
    "  return input_fn(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = tf.contrib.layers.real_valued_column(\"month\")\n",
    "day = tf.contrib.layers.real_valued_column(\"day\")\n",
    "hour = tf.contrib.layers.real_valued_column(\"hour\")\n",
    "minute = tf.contrib.layers.real_valued_column(\"min\")\n",
    "pirstatus = tf.contrib.layers.real_valued_column(\"pirstatus\")\n",
    "isDay = tf.contrib.layers.real_valued_column(\"isDay\")\n",
    "extTemp = tf.contrib.layers.real_valued_column(\"extTemp\")\n",
    "extHumidity = tf.contrib.layers.real_valued_column(\"extHumidity\")\n",
    "loungeTemp = tf.contrib.layers.real_valued_column(\"loungeTemp\")\n",
    "loungeHumidity = tf.contrib.layers.real_valued_column(\"loungeHumidity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_save_checkpoints_secs': 600, '_num_worker_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025184738B38>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_environment': 'local', '_task_type': None, '_model_dir': 'C:\\\\Users\\\\faisal.t\\\\AppData\\\\Local\\\\Temp\\\\tmpueabmsxd', '_session_config': None, '_is_chief': True, '_tf_random_seed': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_evaluation_master': '', '_num_ps_replicas': 0, '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "model_dir = tempfile.mkdtemp()\n",
    "m = tf.contrib.learn.LinearClassifier(feature_columns=[\n",
    "  month, day, hour, minute, pirstatus, isDay,\n",
    "  extTemp, extHumidity, loungeTemp, loungeHumidity],\n",
    "  optimizer=tf.train.FtrlOptimizer(\n",
    "    learning_rate=0.1,\n",
    "    l1_regularization_strength=1.0,\n",
    "    l2_regularization_strength=1.0),\n",
    "  model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\dump\\ml\\learn\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\linear.py:173: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\faisal.t\\AppData\\Local\\Temp\\tmpueabmsxd\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.693147, step = 1\n",
      "INFO:tensorflow:global_step/sec: 730.026\n",
      "INFO:tensorflow:loss = 0.2893, step = 101 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 1063.84\n",
      "INFO:tensorflow:loss = 0.219083, step = 201 (0.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 1063.84\n",
      "INFO:tensorflow:loss = 0.182496, step = 301 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1041.63\n",
      "INFO:tensorflow:loss = 0.159112, step = 401 (0.095 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into C:\\Users\\faisal.t\\AppData\\Local\\Temp\\tmpueabmsxd\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.142792.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._BinaryLogisticHead object at 0x000002518473A908>, 'gradient_clip_norm': None, 'joint_weights': False, 'feature_columns': [_RealValuedColumn(column_name='month', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='day', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='hour', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='min', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='pirstatus', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='isDay', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='extTemp', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='extHumidity', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='loungeTemp', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='loungeHumidity', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)], 'optimizer': <tensorflow.python.training.ftrl.FtrlOptimizer object at 0x000002518473AFD0>})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(input_fn=train_input_fn, steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Features are incompatible with given information. Given features: {'month': <tf.Tensor 'Const:0' shape=(5,) dtype=int64>, 'pirstatus': <tf.Tensor 'Const_4:0' shape=(5,) dtype=int64>, 'isDay': <tf.Tensor 'Const_5:0' shape=(5,) dtype=int64>, 'day': <tf.Tensor 'Const_1:0' shape=(5,) dtype=int64>, 'hour': <tf.Tensor 'Const_2:0' shape=(5,) dtype=int64>, 'min': <tf.Tensor 'Const_3:0' shape=(5,) dtype=int64>, 'extHumidity': <tf.Tensor 'Const_7:0' shape=(5,) dtype=int64>, 'loungeHumidity': <tf.Tensor 'Const_9:0' shape=(5,) dtype=int64>, 'loungeTemp': <tf.Tensor 'Const_8:0' shape=(5,) dtype=float64>, 'extTemp': <tf.Tensor 'Const_6:0' shape=(5,) dtype=int64>}, required signatures: {'day': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'hour': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'min': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'extHumidity': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'month': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'pirstatus': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'loungeHumidity': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'loungeTemp': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'extTemp': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'isDay': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False)}.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6e27d1320adc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"printin results\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\dump\\ml\\learn\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 instructions)\n\u001b[1;32m--> 316\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    318\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32md:\\dump\\ml\\learn\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, input_fn, feed_fn, batch_size, steps, metrics, name, checkpoint_path, hooks, log_progress)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m         log_progress=log_progress)\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meval_results\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\dump\\ml\\learn\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_evaluate_model\u001b[1;34m(self, input_fn, steps, feed_fn, metrics, name, checkpoint_path, hooks, log_progress)\u001b[0m\n\u001b[0;32m    850\u001b[0m       \u001b[0mglobal_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m       \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_eval_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\dump\\ml\\learn\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\estimator.py\u001b[0m in \u001b[0;36m_check_inputs\u001b[1;34m(self, features, labels)\u001b[0m\n\u001b[0;32m    780\u001b[0m         raise ValueError('Features are incompatible with given information. '\n\u001b[0;32m    781\u001b[0m                          \u001b[1;34m'Given features: %s, required signatures: %s.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m                          (str(features), str(self._features_info)))\n\u001b[0m\u001b[0;32m    783\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_features_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_signature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_signatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Features are incompatible with given information. Given features: {'month': <tf.Tensor 'Const:0' shape=(5,) dtype=int64>, 'pirstatus': <tf.Tensor 'Const_4:0' shape=(5,) dtype=int64>, 'isDay': <tf.Tensor 'Const_5:0' shape=(5,) dtype=int64>, 'day': <tf.Tensor 'Const_1:0' shape=(5,) dtype=int64>, 'hour': <tf.Tensor 'Const_2:0' shape=(5,) dtype=int64>, 'min': <tf.Tensor 'Const_3:0' shape=(5,) dtype=int64>, 'extHumidity': <tf.Tensor 'Const_7:0' shape=(5,) dtype=int64>, 'loungeHumidity': <tf.Tensor 'Const_9:0' shape=(5,) dtype=int64>, 'loungeTemp': <tf.Tensor 'Const_8:0' shape=(5,) dtype=float64>, 'extTemp': <tf.Tensor 'Const_6:0' shape=(5,) dtype=int64>}, required signatures: {'day': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'hour': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'min': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'extHumidity': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'month': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'pirstatus': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'loungeHumidity': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'loungeTemp': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'extTemp': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(72)]), is_sparse=False), 'isDay': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(72)]), is_sparse=False)}."
     ]
    }
   ],
   "source": [
    "results = m.evaluate(input_fn=eval_input_fn, steps=1)\n",
    "print(\"printin results\")\n",
    "for key in sorted(results):\n",
    "    print(\"%s: %s\" % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_input_fn():\n",
    "  test_data = {\n",
    "    \"month\":[12],\n",
    "    \"day\":[12],\n",
    "    \"hour\":[22],\n",
    "    \"min\":[0],\n",
    "    \"pirstatus\":[0],\n",
    "    \"isDay\":[1],\n",
    "    \"extTemp\":[35],\n",
    "    \"extHumidity\":[20],\n",
    "    \"loungeTemp\":[12],\n",
    "    \"loungeHumidity\":[30],\n",
    "  }\n",
    "  \n",
    "  continuous_cols = {k: tf.constant(test_data[k])\n",
    "                     for k in test_data}\n",
    "  return continuous_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\faisal.t\\AppData\\Local\\Temp\\tmpueabmsxd\\model.ckpt-500\n",
      "Predictions: [1]\n"
     ]
    }
   ],
   "source": [
    "predictions = list(m.predict(input_fn=predict_input_fn, as_iterable=True))\n",
    "print('Predictions: {}'.format(str(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
